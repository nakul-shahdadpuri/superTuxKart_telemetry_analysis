# SuperTuxKart Telemetry — Analysis Summary

This analysis notebook computes session-level "frustration" scores from SuperTuxKart telemetry. The analysis implements three complementary metrics:

- Ground-based (off-ground) frustration
- Velocity-based (rapid speed change) frustration
- Combined score (blend of ground + velocity)

The calculations, visualizations, and exports are implemented in `analysis.ipynb` in this repository.

## Quick summary

Purpose: quantify and compare player frustration across telemetry sessions to identify problematic tracks, sections, and sessions.

Inputs: CSV telemetry files in this repo matching `telemetry_*.csv` (files may include comment metadata lines starting with `#`).

Outputs (generated by the notebook):

- `frustration_analysis_results_all_scores.csv` — detailed per-session metrics and all three scores
- `combined_frustration.csv`, `ground_based_frustration.csv`, `velocity_based_frustration.csv` — per-score exports
- `frustration_summary_statistics.csv` — summary statistics
- `track_wise_detailed_analysis.csv` — per-track aggregations
- `track_frustrating_sections.csv` — spatial grid results for problematic sections
- Various PNG figures (score comparisons, heatmaps, timelines) saved to the repo (see the notebook for exact filenames)

## Frustration score formulas

Ground-based score (example formula used in the notebook):

$$FrustrationScore_{ground} = w_1 \cdot OffGroundRatio + w_2 \cdot AvgOffGroundDuration$$

With default weights: $w_1=0.4, w_2=0.4$.

Velocity-based score (captures collisions/rapid changes):

$$FrustrationScore_{velocity} = v_1 \cdot RapidChangeRatio + v_2 \cdot AvgRapidChangeMagnitude$$

Combined score (default equal blend):

$$FrustrationScore_{combined} = 0.5 \times FrustrationScore_{ground} + 0.5 \times FrustrationScore_{velocity}$$

All scores are scaled to a 0–100 range in the notebook for easy interpretation.

## Methodology (high level)

1. Load all `telemetry_*.csv` session files, preserving per-file metadata (if present in comment lines).
2. For each session, compute ground-based metrics:
	- Off-ground ratio: proportion of records with `on_ground == 0`.
	- Average off-ground duration: mean duration of off-ground events (detect transitions).
	- Event frequency: off-ground events per minute.
3. For each session, compute velocity-based metrics:
	- Rapid velocity change ratio and frequency (threshold configurable in notebook).
	- Average magnitude of rapid changes; speed standard deviation.
4. Normalize metrics and compute three scores: ground, velocity, and combined.
5. Produce visualizations (comparisons, distributions, per-track analyses, spatial heatmaps) and export CSV files.

## Interpretation (score ranges)

- 0–20: Minimal frustration — smooth sessions
- 20–40: Low — occasional issues
- 40–60: Moderate — noticeable difficulty
- 60–80: High — significant control or collision problems
- 80–100: Extreme — severe session issues

Use the ground score to diagnose jumps/off-track problems and the velocity score to diagnose collisions, sudden stops, or chaotic driving.

## How to run the analysis

1. (Recommended) Create and activate a Python environment. Example with venv:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
```

2. Install required packages (the notebook uses pandas, numpy, matplotlib, seaborn). Example:

```bash
pip install pandas numpy matplotlib seaborn
```

3. Launch the notebook or run it headless:

- To run interactively:

```bash
jupyter notebook analysis.ipynb
```

- To run headless (execute all cells) using nbconvert:

```bash
pip install nbconvert
jupyter nbconvert --to notebook --execute analysis.ipynb --output executed_analysis.ipynb
```

Notes:
- The notebook expects telemetry CSV files in the repository root matching `telemetry_*.csv`.
- Some visualizations sample data for very large sessions to keep plotting responsive.

## Files of interest in this repo

- `analysis.ipynb` — main analysis notebook (contains code, parameters, and explanations).
- `telemetry_*.csv` — raw telemetry sessions (input).
- `frustration_analysis_results_all_scores.csv` etc. — outputs produced by the notebook.

## Tips and next steps

- Tune thresholds and weights in the notebook (velocity threshold, ground vs velocity weights) and re-run to see how rankings change.
- Increase `grid_size` in spatial analysis for higher resolution heatmaps where data density permits.
- Add a small `requirements.txt` if you want reproducible installs; example content:

```text
pandas
numpy
matplotlib
seaborn
```

- Consider adding a lightweight script to batch-run the notebook and archive outputs for repeated experiments.

## Contact

If you need changes to the README structure or want extra export formats (JSON, parquet), open an issue or edit `analysis.ipynb` and re-run.

---
Generated from `analysis.ipynb` — see the notebook for full implementation details and configurable parameters.
